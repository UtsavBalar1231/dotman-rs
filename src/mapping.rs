//! # Commit Mapping Management
//!
//! This module manages the bidirectional mapping between dotman's content-addressed
//! commits and git commits in remote repositories. It provides the critical link that
//! allows dotman to synchronize with git remotes while maintaining its own storage model.
//!
//! ## Purpose
//!
//! Dotman and git have fundamentally different commit ID generation strategies:
//!
//! - **Dotman**: Content-addressed IDs generated from `hash(tree + parent + message + author + timestamp + nanos)`
//! - **Git**: SHA-1 hashes generated by git itself based on commit content and metadata
//!
//! The mapping system bridges this gap by maintaining a persistent, bidirectional mapping
//! that allows dotman to:
//! - Track which dotman commits have been pushed to which remotes
//! - Import git commits from remotes and create corresponding dotman commits
//! - Detect duplicate commits to avoid re-pushing
//! - Support multiple remotes with different commit histories
//!
//! ## Data Structure
//!
//! The mapping is stored in `~/.dotman/remote-mappings.toml` with this structure:
//!
//! ```toml
//! [dotman_to_git.origin]
//! "abc123..." = "def456..."  # dotman_commit_id -> git_commit_id
//!
//! [git_to_dotman.origin]
//! "def456..." = "abc123..."  # git_commit_id -> dotman_commit_id
//!
//! [branch_mappings.main]
//! dotman_head = "abc123..."
//! [branch_mappings.main.git_heads]
//! origin = "def456..."
//! upstream = "789abc..."
//! ```
//!
//! ## Persistence and Durability
//!
//! The mapping file is critical for correct synchronization. It uses several techniques
//! to prevent data loss:
//!
//! ### Atomic Writes
//! All saves use the atomic write pattern:
//! 1. Write to temporary file
//! 2. Call `fsync()` to ensure data hits disk
//! 3. Atomically rename temp file to final path
//!
//! This prevents corruption from crashes or power loss during writes.
//!
//! ### Backup and Recovery
//! - Before each save, creates `.bak` backup of existing file
//! - On load, attempts recovery from backup if main file is corrupted
//! - Validates TOML parsing before accepting a file as valid
//! - Falls back to empty mapping if both files are corrupted (with warning)
//!
//! ### Concurrent Access Protection
//! `MappingManager` uses file locking to prevent concurrent modifications:
//! - Acquires exclusive lock on load
//! - Retries for up to 30 seconds if lock is held
//! - Automatically releases lock on drop
//!
//! ## Usage Patterns
//!
//! ### During Push
//! ```rust,ignore
//! let mut mapping_manager = MappingManager::new(&repo_path)?;
//! mapping_manager.add_and_save(remote, dotman_commit, git_commit)?;
//! mapping_manager.update_branch_and_save(branch, dotman_head, Some((remote, git_head)))?;
//! ```
//!
//! ### During Pull
//! ```rust,ignore
//! let mapping_manager = MappingManager::new(&repo_path)?;
//! if let Some(dotman_commit) = mapping_manager.mapping().get_dotman_commit(remote, git_commit) {
//!     // Already have this commit, just checkout
//! } else {
//!     // Import new commit and create mapping
//! }
//! ```
//!
//! ### Validation
//! ```rust,ignore
//! let warnings = mapping.validate(&config)?;
//! for warning in warnings {
//!     eprintln!("Warning: {}", warning);
//! }
//! ```
//!
//! ## Error Recovery
//!
//! If mappings become corrupted or out of sync:
//! 1. Backup is automatically attempted on load failure
//! 2. Empty mapping allows operations to continue (commits will be re-pushed)
//! 3. Validation detects references to non-existent remotes
//! 4. Manual recovery: delete `remote-mappings.toml` and `.bak`, then re-push

use anyhow::{Context, Result, bail};
use fs4::fs_std::FileExt;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::fs::{self, File};
use std::io::Write;
use std::path::{Path, PathBuf};
use std::time::{Duration, Instant};

/// Manages the mapping between dotman commits and git commits
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CommitMapping {
    /// Map from dotman commit ID to git commit ID for each remote
    dotman_to_git: HashMap<String, HashMap<String, String>>,
    /// Map from git commit ID to dotman commit ID for each remote
    git_to_dotman: HashMap<String, HashMap<String, String>>,
    /// Branch associations
    branch_mappings: HashMap<String, BranchMapping>,
}

/// Represents the mapping between dotman and git commits for a specific branch.
///
/// This struct tracks the current state of a branch in both dotman and git repositories,
/// allowing synchronization between the two systems. Each branch can have multiple git
/// remote heads associated with it.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BranchMapping {
    /// Current dotman commit for this branch
    dotman_head: String,
    /// Current git commit for this branch per remote
    git_heads: HashMap<String, String>,
}

impl CommitMapping {
    /// Create a new empty mapping
    #[must_use]
    pub fn new() -> Self {
        Self {
            dotman_to_git: HashMap::new(),
            git_to_dotman: HashMap::new(),
            branch_mappings: HashMap::new(),
        }
    }

    /// Load mapping from file with corruption recovery
    ///
    /// If the main file is corrupted, attempts to load from backup (.bak).
    /// If both fail, returns an empty mapping and logs the corruption.
    ///
    /// # Errors
    ///
    /// Returns an error if:
    /// - File exists but cannot be read
    /// - Both main file and backup contain invalid TOML
    pub fn load(path: &Path) -> Result<Self> {
        if !path.exists() {
            return Ok(Self::new());
        }

        // Try to load main file
        match Self::try_load(path) {
            Ok(mapping) => Ok(mapping),
            Err(main_error) => {
                eprintln!(
                    "Warning: Mapping file corrupted: {main_error}\nAttempting recovery from backup..."
                );

                // Try backup file
                let backup_path = path.with_extension("bak");
                if backup_path.exists() {
                    match Self::try_load(&backup_path) {
                        Ok(mapping) => {
                            eprintln!("Successfully recovered mapping from backup");
                            // Restore backup to main file
                            if let Err(e) = fs::copy(&backup_path, path) {
                                eprintln!("Warning: Failed to restore backup to main file: {e}");
                            }
                            Ok(mapping)
                        }
                        Err(backup_error) => {
                            eprintln!(
                                "Error: Backup file also corrupted: {backup_error}\nStarting with empty mapping"
                            );
                            // Both files corrupted, return empty mapping
                            Ok(Self::new())
                        }
                    }
                } else {
                    eprintln!("No backup found. Starting with empty mapping");
                    Ok(Self::new())
                }
            }
        }
    }

    /// Try to load and parse mapping file
    fn try_load(path: &Path) -> Result<Self> {
        let content = fs::read_to_string(path)
            .with_context(|| format!("Failed to read mapping file: {}", path.display()))?;

        toml::from_str(&content)
            .with_context(|| format!("Failed to parse mapping file: {}", path.display()))
    }

    /// Save mapping to file using atomic write (temp file + fsync + rename)
    ///
    /// This function implements the atomic write pattern to prevent data corruption
    /// from crashes or power loss during file writes. It ensures that the mapping
    /// file is either fully updated or left unchanged - never in a partial state.
    ///
    /// ## Atomic Write Pattern
    ///
    /// The pattern follows these steps for crash-safe writes:
    ///
    /// ### 1. Create Backup
    /// Before modifying anything, copy existing file to `.bak`. This provides
    /// recovery if the new write fails or produces a corrupted file.
    ///
    /// ### 2. Write to Temporary File
    /// Write complete new content to `.tmp` file. If this fails, original file
    /// remains unchanged. Temp file is in same directory to ensure it's on the
    /// same filesystem (required for atomic rename).
    ///
    /// ### 3. Sync to Disk (fsync)
    /// Call `fsync()` to ensure data is actually written to persistent storage,
    /// not just in OS cache. Without this, a crash could lose the data even
    /// though `write()` succeeded.
    ///
    /// ### 4. Atomic Rename
    /// Rename temp file to final path. On POSIX systems, this is atomic - the
    /// file appears instantly with complete content. No reader will ever see
    /// a partial file. On Windows, this may not be atomic but is still safer
    /// than direct write.
    ///
    /// ## Why This Matters
    ///
    /// The mapping file is critical for synchronization correctness. If it becomes
    /// corrupted:
    /// - Push may duplicate commits to remote
    /// - Pull may fail to recognize existing commits
    /// - Sync history becomes inconsistent
    ///
    /// The atomic write pattern prevents these issues by ensuring writes are
    /// all-or-nothing, even in the face of:
    /// - Process crashes
    /// - System crashes
    /// - Power loss
    /// - Disk errors
    ///
    /// ## Recovery Strategy
    ///
    /// If the final rename fails, we have:
    /// - Original file still intact (unchanged)
    /// - Backup file (if one existed)
    /// - Failed temp file (can be ignored/deleted)
    ///
    /// The `load()` function will use the original/backup to recover.
    ///
    /// Creates a backup (.bak) of the existing file before saving the new version.
    /// This enables recovery if the save operation fails or the file gets corrupted.
    ///
    /// # Errors
    ///
    /// Returns an error if:
    /// - Failed to serialize mapping to TOML
    /// - Failed to create parent directory
    /// - Failed to write or sync temp file
    /// - Failed to rename temp file to final path
    pub fn save(&self, path: &Path) -> Result<()> {
        let content = toml::to_string_pretty(self).context("Failed to serialize mapping")?;

        // Create parent directory if needed
        if let Some(parent) = path.parent() {
            fs::create_dir_all(parent).context("Failed to create mapping directory")?;
        }

        // Create backup of existing file before modifying anything
        // This allows recovery if new write fails or produces corrupt data
        if path.exists() {
            let backup_path = path.with_extension("bak");
            if let Err(e) = fs::copy(path, &backup_path) {
                eprintln!(
                    "Warning: Failed to create backup at {}: {}",
                    backup_path.display(),
                    e
                );
            }
        }

        // Atomic write pattern: write to temp file, fsync, then rename
        // Temp file must be in same directory for atomic rename to work
        let temp_path = path.with_extension("tmp");

        // Write complete new content to temp file
        let mut file = File::create(&temp_path)
            .with_context(|| format!("Failed to create temp file: {}", temp_path.display()))?;

        file.write_all(content.as_bytes())
            .with_context(|| format!("Failed to write to temp file: {}", temp_path.display()))?;

        // Ensure data is persisted to disk before rename
        // Without this, a crash could lose the data even though write() succeeded
        file.sync_all()
            .with_context(|| format!("Failed to sync temp file: {}", temp_path.display()))?;

        // Close file explicitly before rename (required on Windows)
        drop(file);

        // Atomic rename - file appears with complete content instantly
        // On POSIX this is guaranteed atomic; on Windows it's best-effort
        fs::rename(&temp_path, path)
            .with_context(|| format!("Failed to rename temp file to {}", path.display()))?;

        Ok(())
    }

    /// Add a mapping between dotman and git commits
    pub fn add_mapping(&mut self, remote: &str, dotman_commit: &str, git_commit: &str) {
        self.dotman_to_git
            .entry(remote.to_string())
            .or_default()
            .insert(dotman_commit.to_string(), git_commit.to_string());

        self.git_to_dotman
            .entry(remote.to_string())
            .or_default()
            .insert(git_commit.to_string(), dotman_commit.to_string());
    }

    /// Get git commit ID for a dotman commit
    #[must_use]
    pub fn get_git_commit(&self, remote: &str, dotman_commit: &str) -> Option<String> {
        self.dotman_to_git
            .get(remote)
            .and_then(|m| m.get(dotman_commit))
            .cloned()
    }

    /// Get dotman commit ID for a git commit
    #[must_use]
    pub fn get_dotman_commit(&self, remote: &str, git_commit: &str) -> Option<String> {
        self.git_to_dotman
            .get(remote)
            .and_then(|m| m.get(git_commit))
            .cloned()
    }

    /// Update branch mapping
    pub fn update_branch(&mut self, branch: &str, dotman_head: &str, remote: Option<(&str, &str)>) {
        let mapping = self
            .branch_mappings
            .entry(branch.to_string())
            .or_insert_with(|| BranchMapping {
                dotman_head: dotman_head.to_string(),
                git_heads: HashMap::new(),
            });

        mapping.dotman_head = dotman_head.to_string();

        if let Some((remote_name, git_head)) = remote {
            mapping
                .git_heads
                .insert(remote_name.to_string(), git_head.to_string());
        }
    }

    /// Get branch mapping
    #[must_use]
    pub fn get_branch(&self, branch: &str) -> Option<&BranchMapping> {
        self.branch_mappings.get(branch)
    }

    /// Remove all mappings for a remote
    pub fn remove_remote(&mut self, remote: &str) {
        self.dotman_to_git.remove(remote);
        self.git_to_dotman.remove(remote);

        for branch_mapping in self.branch_mappings.values_mut() {
            branch_mapping.git_heads.remove(remote);
        }
    }

    /// Check if a dotman commit has been pushed to a remote
    #[must_use]
    pub fn is_pushed(&self, remote: &str, dotman_commit: &str) -> bool {
        self.dotman_to_git
            .get(remote)
            .is_some_and(|m| m.contains_key(dotman_commit))
    }

    /// Get all mapped dotman commits for a remote
    #[must_use]
    pub fn get_mapped_commits(&self, remote: &str) -> Vec<String> {
        self.dotman_to_git
            .get(remote)
            .map(|m| m.keys().cloned().collect())
            .unwrap_or_default()
    }

    /// Validate mapping consistency against configuration
    ///
    /// Checks that all remotes referenced in the mapping exist in the configuration.
    /// Returns a list of warnings for any inconsistencies found.
    ///
    /// # Errors
    ///
    /// Returns error if config cannot be accessed
    pub fn validate(&self, config: &crate::config::Config) -> Result<Vec<String>> {
        let mut warnings = Vec::new();

        // Check all remotes in dotman_to_git mapping
        for remote in self.dotman_to_git.keys() {
            if config.get_remote(remote).is_none() {
                warnings.push(format!(
                    "Mapping references unknown remote '{remote}' (found in commit mappings)"
                ));
            }
        }

        // Check all remotes in branch mappings
        for (branch, mapping) in &self.branch_mappings {
            for remote in mapping.git_heads.keys() {
                if config.get_remote(remote).is_none() {
                    warnings.push(format!(
                        "Branch '{branch}' mapping references unknown remote '{remote}'"
                    ));
                }
            }
        }

        Ok(warnings)
    }
}

impl Default for CommitMapping {
    fn default() -> Self {
        Self::new()
    }
}

/// Helper to manage mapping file path and persistence operations.
///
/// This struct provides a convenient interface for loading, modifying, and saving
/// commit mappings to disk. It handles the file path management automatically.
/// Holds an exclusive lock on the mapping file to prevent concurrent modifications.
pub struct MappingManager {
    /// Path to the mapping file on disk
    mapping_path: PathBuf,
    /// In-memory commit mapping data
    mapping: CommitMapping,
    /// Lock file to prevent concurrent access
    lock_file: Option<File>,
}

impl MappingManager {
    /// Create a new mapping manager with file locking
    ///
    /// Acquires an exclusive lock on the mapping file to prevent concurrent access.
    /// Will retry for up to 30 seconds if lock is held by another process.
    ///
    /// # Errors
    ///
    /// Returns an error if:
    /// - The mapping file exists but cannot be loaded
    /// - Cannot acquire lock within timeout period
    pub fn new(repo_path: &Path) -> Result<Self> {
        let mapping_path = repo_path.join("remote-mappings.toml");
        let lock_path = repo_path.join("remote-mappings.lock");

        // Try to acquire lock with timeout
        let lock_file = Self::acquire_lock(&lock_path)?;

        // Load mapping after lock is acquired
        let mapping = CommitMapping::load(&mapping_path)?;

        Ok(Self {
            mapping_path,
            mapping,
            lock_file: Some(lock_file),
        })
    }

    /// Acquire exclusive lock on mapping file with timeout
    fn acquire_lock(lock_path: &Path) -> Result<File> {
        // Use shorter timeouts in test mode for faster test execution
        let lock_timeout = if cfg!(test) {
            Duration::from_millis(100)
        } else {
            Duration::from_secs(30)
        };
        let retry_interval = if cfg!(test) {
            Duration::from_millis(10)
        } else {
            Duration::from_millis(100)
        };

        let start = Instant::now();

        loop {
            // Create or open lock file
            let file = File::create(lock_path)
                .with_context(|| format!("Failed to create lock file: {}", lock_path.display()))?;

            // Try to acquire exclusive lock (non-blocking first)
            match file.try_lock_exclusive() {
                Ok(true) => return Ok(file),
                Ok(false) | Err(_) if start.elapsed() < lock_timeout => {
                    // Lock held by another process, wait and retry
                    std::thread::sleep(retry_interval);
                }
                Ok(false) | Err(_) => {
                    bail!(
                        "Failed to acquire lock on mapping file after {}s. \
                         Another dotman operation may be in progress.",
                        lock_timeout.as_secs()
                    );
                }
            }
        }
    }

    /// Get a reference to the mapping
    #[must_use]
    pub const fn mapping(&self) -> &CommitMapping {
        &self.mapping
    }

    /// Get a mutable reference to the mapping
    pub const fn mapping_mut(&mut self) -> &mut CommitMapping {
        &mut self.mapping
    }

    /// Save the mapping to disk
    ///
    /// # Errors
    ///
    /// Returns an error if the mapping cannot be saved
    pub fn save(&self) -> Result<()> {
        self.mapping.save(&self.mapping_path)
    }

    /// Add a mapping and save
    ///
    /// # Errors
    ///
    /// Returns an error if the mapping cannot be saved to disk
    pub fn add_and_save(
        &mut self,
        remote: &str,
        dotman_commit: &str,
        git_commit: &str,
    ) -> Result<()> {
        self.mapping.add_mapping(remote, dotman_commit, git_commit);
        self.save()
    }

    /// Update branch and save
    ///
    /// # Errors
    ///
    /// Returns an error if the mapping cannot be saved to disk
    pub fn update_branch_and_save(
        &mut self,
        branch: &str,
        dotman_head: &str,
        remote: Option<(&str, &str)>,
    ) -> Result<()> {
        self.mapping.update_branch(branch, dotman_head, remote);
        self.save()
    }
}

impl Drop for MappingManager {
    fn drop(&mut self) {
        // Lock is automatically released when file is dropped
        if let Some(lock_file) = self.lock_file.take() {
            // Explicitly unlock (though it happens automatically on drop)
            let _ = lock_file.unlock();
        }
    }
}
